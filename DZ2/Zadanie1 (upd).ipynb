{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DZ2.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RIJSpenmO0uT",
        "outputId": "7c8245ff-c43f-4f9a-a240-c58754385f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Bzrm/Files/master/anna_karenina1.txt\n",
        "!wget https://raw.githubusercontent.com/Bzrm/Files/master/besy_dostoevsky1.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-24 19:59:17--  https://raw.githubusercontent.com/Bzrm/Files/master/anna_karenina1.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 573966 (561K) [text/plain]\n",
            "Saving to: ‘anna_karenina1.txt’\n",
            "\n",
            "\ranna_karenina1.txt    0%[                    ]       0  --.-KB/s               \ranna_karenina1.txt  100%[===================>] 560.51K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2019-10-24 19:59:18 (8.84 MB/s) - ‘anna_karenina1.txt’ saved [573966/573966]\n",
            "\n",
            "--2019-10-24 19:59:21--  https://raw.githubusercontent.com/Bzrm/Files/master/besy_dostoevsky1.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 540787 (528K) [text/plain]\n",
            "Saving to: ‘besy_dostoevsky1.txt’\n",
            "\n",
            "besy_dostoevsky1.tx 100%[===================>] 528.11K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2019-10-24 19:59:22 (8.31 MB/s) - ‘besy_dostoevsky1.txt’ saved [540787/540787]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGLyyyrWTyIV",
        "colab_type": "text"
      },
      "source": [
        "### Задание 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WlOUnfb-PKA4",
        "colab": {}
      },
      "source": [
        "dostoevsky = open('besy_dostoevsky1.txt').read()\n",
        "tolstoy = open('anna_karenina1.txt').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E_xokDWaPZ0o",
        "colab": {}
      },
      "source": [
        "from string import punctuation\n",
        "import numpy as np\n",
        "\n",
        "def normalize(text):\n",
        "    normalized_text = [word.strip(punctuation) for word \\\n",
        "                                                            in text.lower().split()]\n",
        "    normalized_text = [word for word in normalized_text if word]\n",
        "    return normalized_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-95cgAHSPhXB",
        "colab": {}
      },
      "source": [
        "norm_dostoevsky = normalize(dostoevsky)\n",
        "norm_tolstoy = normalize(tolstoy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GAF9oFRWPoof",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZEoRCEKxPuw_",
        "colab": {}
      },
      "source": [
        "vocab_dostoevsky = Counter(norm_dostoevsky)\n",
        "vocab_tolstoy = Counter(norm_tolstoy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WMJtFK6HP4SY",
        "outputId": "4e258fc3-3702-46b8-b014-b906ede00fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download ('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "def ngrammer2(tokens, n=2):\n",
        "    ngrams2 = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams2.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams2\n",
        "def ngrammer3(tokens, n=3):\n",
        "    ngrams3 = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams3.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams3"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QkSNnr5aP9MI",
        "colab": {}
      },
      "source": [
        "sentences_dostoevsky = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] + ['<end>'] for text in sent_tokenize(dostoevsky)]\n",
        "sentences_tolstoy = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] + ['<end>'] for text in sent_tokenize(tolstoy)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KUVd-zdYQxMI",
        "colab": {}
      },
      "source": [
        "unigrams_dostoevsky = Counter()\n",
        "bigrams_dostoevsky = Counter()\n",
        "trigrams_dostoevsky = Counter()\n",
        "\n",
        "for sentence in sentences_dostoevsky:\n",
        "    unigrams_dostoevsky.update(sentence)\n",
        "    bigrams_dostoevsky.update(ngrammer2(sentence))\n",
        "    trigrams_dostoevsky.update(ngrammer3(sentence))\n",
        "\n",
        "\n",
        "unigrams_tolstoy = Counter()\n",
        "bigrams_tolstoy = Counter()\n",
        "trigrams_tolstoy = Counter()\n",
        "\n",
        "for sentence in sentences_tolstoy:\n",
        "    unigrams_tolstoy.update(sentence)\n",
        "    bigrams_tolstoy.update(ngrammer2(sentence))\n",
        "    trigrams_tolstoy.update(ngrammer3(sentence))\n",
        "    \n",
        "   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D-7P2AdfR68D",
        "colab": {}
      },
      "source": [
        "matrix_dostoevsky = np.zeros((len(bigrams_dostoevsky), \n",
        "                   len(unigrams_dostoevsky)))\n",
        "id2bigram_dostoevsky = list(bigrams_dostoevsky)\n",
        "bigram2id_dostoevsky = {bigram:n for n, bigram in enumerate(id2bigram_dostoevsky)}\n",
        "id2word_dostoevsky = list(unigrams_dostoevsky)\n",
        "word2id_dostoevsky = {word:i for i, word in enumerate(id2word_dostoevsky)}\n",
        "\n",
        "for ngram in trigrams_dostoevsky:\n",
        "  word1, word2, word3 = ngram.split()\n",
        "  for bigram in bigrams_dostoevsky:\n",
        "    wordA, wordB = bigram.split()\n",
        "    if wordA == word1 and wordB == word2:\n",
        "      matrix_dostoevsky[bigram2id_dostoevsky[bigram]][word2id_dostoevsky[word3]] =  (trigrams_dostoevsky[ngram]/bigrams_dostoevsky[bigram])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEkfIR9zaCUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(matrix, id2word, bigram2id, n=100, start=['<start>','<start>']):\n",
        "    text = []\n",
        "    current_bigram = start\n",
        "    current_idx = bigram2id[' '.join(current_bigram)]\n",
        "    \n",
        "    for i in range(n):\n",
        "        \n",
        "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "        text.append(id2word[chosen])\n",
        "        \n",
        "        if id2word[chosen] == '<end>':\n",
        "          current_bigram = start\n",
        "          current_idx = bigram2id[' '.join(current_bigram)]\n",
        "        else:\n",
        "          current_bigram = [current_bigram[1], id2word[chosen]]\n",
        "          current_idx = bigram2id[' '.join(current_bigram)]\n",
        "          \n",
        "    return ' '.join(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgOryFQqOtC4",
        "colab_type": "code",
        "outputId": "907e9543-e88a-4ee9-fe31-719f5fa390c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "print(generate(matrix_dostoevsky, id2word_dostoevsky, bigram2id_dostoevsky).replace('<end>', '\\n'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "он не раз \n",
            " к одному только липутину я не про страх будет больно \n",
            " но ведь это всё равно у меня и — покраснел \n",
            " одна странная мысль \n",
            " — не только не знаю а жену его совсем не то что из этих пяти человек наверное четверо не имели при этом волосы до плеч \n",
            " — о поручении вы прибавили — резко заметил гость — поручения совсем не знаю кого ты привел что-то не помню этакого — поглядела она на меня и спрашивают «конфиденциально» как я причесала и не напоминайте \n",
            " мы в залу \n",
            " всё однако к великому\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWuIS1lcPvus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_tolstoy = np.zeros((len(bigrams_tolstoy), \n",
        "                   len(unigrams_tolstoy)))\n",
        "id2bigram_tolstoy = list(bigrams_tolstoy)\n",
        "bigram2id_tolstoy = {bigram:n for n, bigram in enumerate(id2bigram_tolstoy)}\n",
        "id2word_tolstoy = list(unigrams_tolstoy)\n",
        "word2id_tolstoy = {word:i for i, word in enumerate(id2word_tolstoy)}\n",
        "\n",
        "for ngram in trigrams_tolstoy:\n",
        "  word1, word2, word3 = ngram.split()\n",
        "  for bigram in bigrams_tolstoy:\n",
        "    wordA, wordB = bigram.split()\n",
        "    if wordA == word1 and wordB == word2:\n",
        "      matrix_tolstoy[bigram2id_tolstoy[bigram]][word2id_tolstoy[word3]] =  (trigrams_tolstoy[ngram]/bigrams_tolstoy[bigram])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y7p0uv3QIDr",
        "colab_type": "code",
        "outputId": "64bac3f4-45b0-4e58-848d-65e298e62faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "print(generate(matrix_tolstoy, id2word_tolstoy, bigram2id_tolstoy ).replace('<end>', '\\n'))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "анна подняла сухую худую руку долли поцеловала ее и заставляла делать то чего нельзя сделать \n",
            " ничего батюшка \n",
            " – боже мой \n",
            " нет надоело \n",
            " хозяин улыбался одобрительно \n",
            " – говорила княгиня чуть не сбив с ног кузьму выскочила тоже и визжала терлась об его колени поднималась и хотела бежать назад но отец удержал ее – что же делать \n",
            " ну какое там сокровище купили вы недавно на толкучке \n",
            " как это могло огорчать меня \n",
            " он прошелся два раза своими твердыми шагами по комнате вещей пред открытою шифоньеркой из которой она выбирала что-то \n",
            " ты знаешь – настолько\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8k0wdWETvRz",
        "colab_type": "text"
      },
      "source": [
        "А теперь, вроде, неплохо. Хотя у Достоевского хороший (грамматически связный) результат выдаётся всё равно только в диапазоне трёх-четырёх слов([к одному только липутину] [я не про страх]  [будет больно]).У Толстого лучше ([анна подняла сухую худую руку долли поцеловала ее] и [заставляла делать то чего нельзя сделать]) Возможно потому, что сокращение вышло не совсем пропорциональным и текст Толстого оказался больше. "
      ]
    }
  ]
}